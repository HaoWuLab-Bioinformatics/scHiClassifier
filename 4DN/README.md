## Overview
1. The folder "**4DN_Data**" contains the raw data from 4115 cells of five types, namely GM12878, H1Esc, HFF, IMR90, and HAP1.  
2. The folder "**4DN_features**" serves to store the feature sets generated by the code in the "**Feature_extraction**" folder.  
3. The folder "**Feature_extraction**" contains the code used to generate the feature sets, wherein "**generate_feature_NBCP.py**" is utilized to generate the NBCP feature set, "**generate_feature_PSDCP.py**" is utilized to generate the PSDCP feature set, "**generate_feature_SBCP.py**" is utilized to generate the SBCP feature set, and "**generate_feature_SSDCP.py**" is utilized to generate the SSDCP feature set. Additionally, "**methods.py**" encompasses the code for some functions co-utilized by the above four code files.  
4. The folder "**train&test**" contains the code details for the schiClassifier framework to be trained on the training sets and tested on the testing sets. The subfolder "**train&test_result**" is designated for storing the evaluation results of the model performance on the testing sets, after being trained on the training sets. The "**focal_loss_GPU0.py**", "**focal_loss_GPU1.py**", "**focal_loss_GPU2.py**" and "**focal_loss_GPU3.py**" files refer to the code that calls different GPUs to compute the "**focal loss**" loss function, respectively. The file "**main.py**" contains the main body of code for the schiClassifier framework to be trained on the training sets and tested on the testing sets, while the file "**method.py**" contains the declarations of certain functions and classes invoked by the "**main.py**".
5. The folder "**train&val**" contains the code details for the schiClassifier framework to be trained on the training subsets and validated on the validation subsets. The subfolder "**model_sa+Conv1d_earlystopping**" is designated for storing the dictionary composed of all weight parameters corresponding to the model at the point of early stopping on the validation subsets. The subfolder "**train&val_result**" is designated for storing the evaluation results of the model performance on the validation subsets, after being trained on the training subsets. The "**focal_loss_GPU0.py**", "**focal_loss_GPU1.py**", "**focal_loss_GPU2.py**" and "**focal_loss_GPU3.py**" refer to the code that calls different GPUs to compute the "**focal loss**" loss function, respectively. The file "**main.py**" contains the main body of code for the schiClassifier framework to be trained on the training subsets and validated on the validation subsets, while the file "**method.py**" contains the declarations of certain functions and classes invoked by the "**main.py**". The file "**pytorch_tools.py**" contains the declarations for several utility classes including EarlyStopping, which are invoked by the code in the "**main.py**" file.
6. The file "**combo_hg19.genomesize**" includes the lengths of each of the 23 chromosomes in a human cell, with the unit of measurement being the number of base pairs contained in the chromosome.

## Usage 
At each step, we have given the execution code of NHLF cell line as an example, and users will get the test results of Enhancer-MDLF on NHLF after executing all of them according to the example.
### Step 0. Prepare dataset
We have provided enhancer training and test set data and labels for eight cell lines in the following directory:  
training set data : 'data/train/${cell line name}.fasta'  (**e.g.** 'data/train/NHLF.fasta')  
training set label : 'data/train/${cell line name}_y_train.txt'  (**e.g.** 'data/train/NHLF_y_train.txt')  
test set data : 'data/test/${cell line name}.fasta'  (**e.g.** 'data/test/NHLF.fasta')  
test set label : 'data/test/${cell line name}_y_test.txt'  (**e.g.** 'data/test/NHLF_y_test.txt')  
If users want to run Enhancer-MDLF using their own dataset , please organize the data in the format described above. 
### Step 1. Setup environment
First, in order to avoid conflicts between the project's packages and the user's commonly used environment, we recommend that users create a new conda virtual environment named test through the following script.  
`conda create -n test python=3.8`  
`conda activate test`  
Later, users can install all dependencies of the project by running the script:  
`pip install -r requirements.txt`  
### Step 2. Extract features of enhancers
Before running Enhancer-MDLF,users should extract features of enhancers through run the script to extract dna2vec-based features and motif-based features as follows:  
#### necessary input  
input = 'the data file from which you want to extract features.The file naming format is the same as in step 0.'  
cell_line = 'the cell line name for feature exrtraction'  
set = 'the extracted data for training or testing'  
#### run the script
(1) extract dna2vec feature  
`python dna2vec_code.py --input_file ${input} --cell_line ${cell_line} --set ${set}`   
**e.g.**`python dna2vec_code.py --input_file data/train/NHLF.fasta --cell_line NHLF --set train`  
**e.g.**`python dna2vec_code.py --input_file data/test/NHLF.fasta --cell_line NHLF --set test`  
(2) extract motif feature  
`python motif_find.py --input_file ${input} --cell_line ${cell_line} --set ${set}`  
**e.g.**`python motif_find.py --input_file data/train/NHLF.fasta --cell_line NHLF --set train`  
**e.g.**`python motif_find.py --input_file data/test/NHLF.fasta --cell_line NHLF --set test`  
The output feature files will be saved in the 'feature' directory
### Step 3. Run Enhancer-MDLF:  
Users can run the script as follows to compile and run Enhancer-MDLF:    
#### necessary input  
cell_line = 'the cell line name for train and prediction'  
#### run the script
`python main.py --cell_line ${cell_line}`    
e.g.`python main.py --cell_line NHLF`   
